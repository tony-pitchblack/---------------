{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "from scipy import stats \n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "\n",
    "from pingouin import multivariate_normality\n",
    "\n",
    "from sample_size_calculation import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_cluster = pd.read_csv(\"Данные/processed/clustering-data-structure-volume.csv\")\n",
    "data_to_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "    return linkage_matrix\n",
    "\n",
    "feature_labels_assets = [\"Здания\", \"Машины и оборудование\", \\\n",
    "    \"Сооружения\", \"Транспортные средства\"]\n",
    "# feature_labels_assets = [\"Здания\", \"Машины и оборудование\", \\\n",
    "#     \"Сооружения\"]\n",
    "X = data_to_cluster.loc[:, feature_labels_assets]\n",
    "# scaler = MinMaxScaler()\n",
    "# X[\"Всего основных фондов\"] = scaler.fit_transform(X.loc[:, [\"Всего основных фондов\"]])\n",
    "\n",
    "linkage_types = ['ward', 'complete', 'average', 'single']\n",
    "cutoff_thresholds = [0.55, 0.5, 0.38, 0.25]\n",
    "linkage_colors = dict(zip(linkage_types, cutoff_thresholds))\n",
    "labels = [' Уорда', 'Полной связи', \"Средней связи\", \"Ближнего соседа\"]\n",
    "linkage_labels = dict(zip(linkage_types, labels))\n",
    "\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "hclust = dict()\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "axs_indices = [(i, j) for i in range(2) for j in range(2)]\n",
    "for linkage_type, axs_ind in zip(linkage_types, axs_indices):\n",
    "    model = AgglomerativeClustering(linkage=linkage_type, distance_threshold=0, n_clusters=None)\n",
    "    clustering = model.fit(X)\n",
    "    axs[axs_ind].set_title(linkage_labels[linkage_type])\n",
    "    axs[axs_ind].axhline(y=linkage_colors[linkage_type], linestyle='dashed', color='black')\n",
    "    linkage_matrix = plot_dendrogram(\n",
    "        clustering,\n",
    "        truncate_mode=\"level\",\n",
    "        p=3,\n",
    "        ax=axs[axs_ind], \n",
    "        labels=data_to_cluster[\"Код раздела\"].to_list(),\n",
    "        color_threshold = linkage_colors[linkage_type]\n",
    "        # orientation='right'\n",
    "        )\n",
    "    \n",
    "    hclust[linkage_type] = {\n",
    "        \"clustering\": clustering,\n",
    "        \"linkage_matrix\": linkage_matrix\n",
    "    }\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_x = [4., 4., 4., 3.]\n",
    "chosen_y = [0.421457, 0.475347, 0.487812, 0.953896]\n",
    "scores = []\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "axs_indices = [(i, j) for i in range(2) for j in range(2)]\n",
    "for i, linkage_type, axs_ind in zip(range(4), linkage_types, axs_indices):\n",
    "    model = AgglomerativeClustering(linkage=linkage_type)\n",
    "    visualizer = KElbowVisualizer(\n",
    "        model,\n",
    "        k=(1,15),\n",
    "        ax=axs[axs_ind], \n",
    "        timings=False,\n",
    "        title = linkage_labels[linkage_type],\n",
    "        locate_elbow=True\n",
    "        )\n",
    "    visualizer.fit(X)\n",
    "    visualizer.finalize()\n",
    "    ticks = axs[axs_ind].get_xticks()\n",
    "    ticks = np.append(ticks, chosen_x[i])\n",
    "    axs[axs_ind].set_xticks(ticks)\n",
    "    axs[axs_ind].plot([chosen_x[i]], [chosen_y[i]], \\\n",
    "        marker='o', ms=10, c='red')\n",
    "    # if linkage_type == 'single':\n",
    "    #     axs[axs_ind].axvline(x=linkage_chosen_k[linkage_type], color='red', \\\n",
    "    #         linestyle='dashdot')\n",
    "    scores.append(visualizer.k_scores_)\n",
    "fig.tight_layout()\n",
    "# print()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(scores)\n",
    "df = df.transpose().rename(columns=dict(zip(df.columns, labels)))\n",
    "df = df.rename(index=dict(zip(df.index, range(1,df.shape[0]))))\n",
    "pd.set_option('display.precision', 2)\n",
    "# pd.reset_option('display.precision')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_thresholds = cutoff_thresholds\n",
    "cluster_mapping = data_to_cluster.loc[:, :\"Код раздела\"]\n",
    "# cluster_mapping = data_to_cluster\n",
    "cluser_count = []\n",
    "for linkage_type, t in zip(linkage_types, cutoff_thresholds):\n",
    "    enum = fcluster(hclust[linkage_type][\"linkage_matrix\"], t=t, criterion='distance')\n",
    "    model = hclust[linkage_type][\"clustering\"]\n",
    "    # hclust[linkage_type][\"score\"] = metrics.silhouette_score(X, enum, metric='euclidean')\n",
    "    cluster_mapping[linkage_type] = enum\n",
    "    cluser_count.append(cluster_mapping.nunique()[linkage_type])\n",
    "# ind = data_to_cluster[data_to_cluster['Код раздела'].isin(['A','B'])].index\n",
    "# data_to_cluster = data_to_cluster.drop(ind)\n",
    "# cluster_mapping.head()\n",
    "# data_to_cluster.head()\n",
    "# cluser_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clustered = pd.merge(data_to_cluster, cluster_mapping, 'inner', \"Код раздела\")\n",
    "data_clustered.to_csv('Данные/processed/clustering-mapping-structure.csv', index=False) \n",
    "data_clustered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu_num = 4\n",
    "pd.reset_option('all')\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# data_clustered[data_clustered[\"ward\"] == clu_num].loc[:, [\"Название раздела\"]]\n",
    "data_clustered[data_clustered[\"ward\"] == clu_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_regr = pd.read_csv('Данные/processed/regression-data-v0.csv')\n",
    "feature_labels_douglas = ['ROFA', 'K','L', 't']\n",
    "data_for_regr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_for_regr.loc[:, \"ROFA\":\"t\"]\n",
    "std_arr = X.std().to_numpy()\n",
    "print(std_arr)\n",
    "err_rate = 0.1\n",
    "# delta_arr = X.mean().to_numpy() * err_rate\n",
    "delta_arr = std_arr / 2.5\n",
    "N = X.shape[0]\n",
    "print(N)\n",
    "\n",
    "sample_sizes = [sample_size_repetitive(0.05, delta, N, std=std) \\\n",
    "    for delta, std in zip(delta_arr, std_arr)]\n",
    "sample_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_regr[[*feature_labels_douglas]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_cluster = pd.read_csv(\"Данные/processed/regression-data-v0.csv\")\n",
    "data_clustered_full = pd.merge(data_to_cluster, cluster_mapping, 'inner', \"Код раздела\")\n",
    "data_clustered_full = data_clustered_full.drop(columns=['Название раздела'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_regr_cl = pd.merge(data_for_regr, cluster_mapping, 'inner', \"Код раздела\")\n",
    "data_for_regr_cl.loc[:, \"ROFA\":\"L\"] = data_for_regr_cl.loc[:, \"ROFA\":\"L\"].apply(lambda x: np.log(x))\n",
    "data_for_regr_cl = data_for_regr_cl.rename(columns={\"ROFA\": \"ln_ROFA\", \"K\": \"ln_K\", \"L\": \"ln_L\"})\n",
    "data_for_regr_cl.to_csv(\"Данные/processed/regression-data-log-ward-v1.csv\", index=False)\n",
    "data_for_regr_cl.groupby('ward').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# feature_labels_douglas_ln = ['ln_ROFA', 'ln_K', 'ln_L', 't']\n",
    "# sns.pairplot(data_clustered_full.loc[:, ['Код раздела', *feature_labels_douglas]] \\\n",
    "#              [data_for_regr_cl['ward'] == 2], hue='Код раздела', corner=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_type = 'ward'\n",
    "regr_metrics_all = []\n",
    "for cluster_id in data_for_regr_cl[linkage_type].unique():\n",
    "    cluster = data_for_regr_cl[data_for_regr_cl[linkage_type] == cluster_id]\n",
    "    data_for_regr_cl[data_for_regr_cl['ward'] == cluster_id]\n",
    "\n",
    "    regr_metrics = {}\n",
    "    X = cluster.loc[:, [\"ln_K\", \"ln_L\", \"t\"]]\n",
    "    X = sm.add_constant(X)\n",
    "    Y = cluster.loc[:, [\"ln_ROFA\"]]\n",
    "    regression = sm.OLS(Y, X, hasconst=True)\n",
    "    # if cluster_id == 2:\n",
    "    #     result_OLS = regression.fit_regularized(alpha=0, L1_wt=0)\n",
    "    # else:\n",
    "    result_OLS = regression.fit()\n",
    "\n",
    "    n=X[X.columns[0]].count()\n",
    "    regr_metrics['cluster_id'] = cluster_id\n",
    "    regr_metrics['obs_count'] = n\n",
    "\n",
    "    regr_metrics['shapiro-wilk'] = stats.shapiro(result_OLS.resid).pvalue\n",
    "    regr_metrics['JB'] = jarque_bera(result_OLS.resid)[1]\n",
    "\n",
    "    white_res = sm.stats.diagnostic.het_white(result_OLS.resid, regression.exog)\n",
    "    white_lm_pvalue = white_res[1]\n",
    "    regr_metrics['white_lm_pvalue'] = white_lm_pvalue\n",
    "\n",
    "    dw = sm.stats.stattools.durbin_watson(result_OLS.resid)\n",
    "    regr_metrics['D-W'] = dw\n",
    "\n",
    "    VIF_array = []\n",
    "    for exog_idx in range(1, regression.exog.shape[1]):\n",
    "        VIF = variance_inflation_factor(regression.exog, exog_idx)\n",
    "        VIF_array.append(round(VIF, 2))\n",
    "        regr_metrics[f'VIF_x{exog_idx}'] = VIF\n",
    "    # print('-- VIF:', VIF_array)\n",
    "    hz, hz_pval, normal = multivariate_normality(regression.exog)\n",
    "    regr_metrics['HZ'] = hz_pval\n",
    "    regr_metrics_all.append(regr_metrics)\n",
    "\n",
    "    # print('\\nLinkage: {l}, cluster {c}, n: {n}'.format(l=linkage_type, c=cluster_id, n=n))\n",
    "    # print(result_OLS.summary())    \n",
    "    # print('-- White\\'s test pvalue: ', white_lm_pvalue)\n",
    "    # print('-- VIF:', VIF_array)\n",
    "\n",
    "    # X_resid = X.iloc[:, 1:]\n",
    "    # X_resid = X_resid.join(pd.DataFrame({\"e\": result_OLS.resid}))\n",
    "    # X_resid = X_resid.join(data_for_regr_cl['Код раздела'])\n",
    "    # g = sns.PairGrid(X_resid, y_vars=[\"e\"], x_vars=[\"ln_K\", \"ln_L\", \"t\"], hue='Код раздела', height=4)\n",
    "    # # g.map(sns.regplot, color=\".3\", ci=None)\n",
    "    # g.map(sns.scatterplot)\n",
    "    # g.set(ylim=(-1.5, 1.5), yticks=[-1.5, -1, 0, 1, 1.5])\n",
    "\n",
    "pd.reset_option('display.precision')\n",
    "regr_metrics_all = pd.DataFrame(regr_metrics_all)\n",
    "# print(regr_metrics_all)\n",
    "regr_metrics_all[['shapiro-wilk', 'cluster_id']].sort_values(by='cluster_id') \\\n",
    "    .to_clipboard()\n",
    "# plt.show()\n",
    "\n",
    "# CHECK HETEROSCEDASTISITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for multivariate normality\n",
    "group_id = 3\n",
    "d_clust_g3 = data_clustered_full[data_clustered_full['ward'] == group_id]\n",
    "\n",
    "print(d_clust_g3.shape)\n",
    "hz, pval, normal = multivariate_normality(d_clust_g3.loc[:, ['K', 'L', 't']])\n",
    "print(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from help_funcs import isMahalanobisOutlier\n",
    "is_outlier, squared_distances = isMahalanobisOutlier(d_clust_g3.loc[:, ['ROFA', 'K', 'L']]\n",
    "                                  .to_numpy(), 0.55)\n",
    "d_clust_g3['is_outlier'] = is_outlier\n",
    "d_clust_g3['m_dist'] = squared_distances\n",
    "d_clust_g3.loc[:, [ 'ROFA', 'K', 'L']]\n",
    "\n",
    "# sns.histplot(d_clust_g3, x='m_dist')\n",
    "# plt.show()\n",
    "# sns.boxenplot(d_clust_g3, x='m_dist', k_depth='proportion', outlier_prop=0.5)\n",
    "# plt.show()\n",
    "# sns.boxenplot(d_clust_g3, x='m_dist', k_depth='trustworthy', trust_alpha=0.05)\n",
    "\n",
    "g = sns.PairGrid(data=d_clust_g3.loc[:, ['ROFA', 'K', 'L']], corner=True)\n",
    "g.map(sns.scatterplot, hue=d_clust_g3['Код раздела'], style=d_clust_g3['is_outlier'], \n",
    "      markers={True: 'X', False: 'o'})\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHUFFLE OUTLIERS\n",
    "# Compute distortion first\n",
    "from yellowbrick.cluster import distortion_score\n",
    "data_shuffle1 = data_clustered_full.loc[:, ['Код раздела', *feature_labels_douglas, 'ward']].copy()\n",
    "distortion1 = distortion_score(data_shuffle1[[*feature_labels_douglas]],\n",
    "                               data_shuffle1['ward'])\n",
    "data_shuffle2 = data_shuffle1.copy()\n",
    "data_shuffle2.loc[data_shuffle2['Код раздела'] == 'G', 'ward'] = 4\n",
    "distortion2 = distortion_score(data_shuffle2[[*feature_labels_douglas]],\n",
    "                               data_shuffle2['ward'])\n",
    "print(distortion1, distortion2)\n",
    "\n",
    "data_shuffle2_cl4 = data_shuffle2[data_shuffle2['ward'] == 4]\n",
    "g = sns.PairGrid(data=data_shuffle2_cl4.loc[:, ['ROFA', 'K', 'L']], corner=True)\n",
    "g.map(sns.scatterplot, hue=data_shuffle2_cl4['Код раздела'],\n",
    "      # style=data_shuffle2_cl4['is_outlier'], \n",
    "      markers={True: 'X', False: 'o'})\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE OUTLIERS\n",
    "dc = data_clustered_full.loc[:, [*feature_labels_douglas, 'ward']].copy()\n",
    "centroids = dc.groupby('ward').mean()\n",
    "to_move = data_clustered_full[data_clustered_full[\"Код раздела\"] == 'G'].loc[:, \\\n",
    "    [*feature_labels_douglas]]\n",
    "distances = centroids.apply(lambda c: np.linalg.norm(c - to_move.mean()),\n",
    "    axis='columns')\n",
    "distances\n",
    "# cluster_mapping.loc[cluster_mapping['Код раздела'] == 'G', 'ward'] = 1\n",
    "# cluster_mapping.loc[cluster_mapping['Код раздела'] == 'G', 'ward'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECT HETEROSCEDASTISITY\n",
    "from help_funcs import get_whites_regr\n",
    "import warnings\n",
    "\n",
    "linkage_type = 'ward'\n",
    "# data_for_regr_cl = data_shuffle2.copy()\n",
    "# data_for_regr_cl.loc[:, \"ROFA\":\"L\"] = data_for_regr_cl.loc[:, \"ROFA\":\"L\"].apply(lambda x: np.log(x))\n",
    "# data_for_regr_cl = data_for_regr_cl.rename(columns={\"ROFA\": \"ln_ROFA\", \"K\": \"ln_K\", \"L\": \"ln_L\"})\n",
    "regr_metrics_all = []\n",
    "\n",
    "for cluster_id in [1, 4]:\n",
    "    regr_metrics = {}\n",
    "\n",
    "    cluster = data_for_regr_cl[data_for_regr_cl[linkage_type] == cluster_id]\n",
    "    X = cluster.loc[:, [\"ln_K\", \"ln_L\", \"t\"]]\n",
    "    X = sm.add_constant(X)\n",
    "    Y = cluster.loc[:, [\"ln_ROFA\"]]\n",
    "    regression = sm.OLS(Y, X, hasconst=True)\n",
    "    result_OLS = regression.fit()\n",
    "\n",
    "\n",
    "    n=X[X.columns[0]].count()\n",
    "    for k in range(1, X.shape[1]):\n",
    "        regr_white_WLS, whites_terms = get_whites_regr(regression, k)\n",
    "        result_white_WLS = regr_white_WLS.fit()\n",
    "        print('\\nLinkage: {l}, cluster {c}, n: {n}'.format(l=linkage_type, c=cluster_id, n=n))\n",
    "        print(f'White terms: {whites_terms}')\n",
    "        print(result_white_WLS.summary())\n",
    "        white_lm_pvalue = sm.stats.diagnostic.het_white(result_white_WLS.resid, X)[1]\n",
    "        print('-- White\\'s test pvalue: ', white_lm_pvalue)\n",
    "    \n",
    "    \n",
    "    whites_regr, whites_terms = get_whites_regr(regression, full=True)\n",
    "    result_white_WLS = whites_regr.fit()\n",
    "\n",
    "    result_OLS = result_white_WLS\n",
    "    # print('\\nLinkage: {l}, cluster {c}, n: {n}'.format(l=linkage_type, c=cluster_id, n=n))\n",
    "    # print(result_OLS.summary())    \n",
    "    \n",
    "    regr_metrics['cluster_id'] = cluster_id\n",
    "    regr_metrics['obs_count'] = n\n",
    "\n",
    "    white_lm_pvalue = sm.stats.diagnostic.het_white(result_OLS.resid, X)[1]\n",
    "    print('-- White\\'s test pvalue: ', white_lm_pvalue)\n",
    "    regr_metrics['white_lm_pvalue'] = white_lm_pvalue\n",
    "\n",
    "    # SSE_i = (result_OLS.resid ** 2).sum()\n",
    "    # SSE_all.append(SSE_i)\n",
    "    # print('-- SSE_i: ', round(SSE_i, 2))  \n",
    "\n",
    "    for exog_idx in range(1, regression.exog.shape[1]):\n",
    "        VIF = variance_inflation_factor(regression.exog, exog_idx)\n",
    "        regr_metrics[f'VIF_x{exog_idx}'] = VIF\n",
    "    # print('-- VIF:', VIF_array)\n",
    "    regr_metrics['JB'] = jarque_bera(result_OLS.resid)[1]\n",
    "    hz, hz_pval, normal = multivariate_normality(regression.exog)\n",
    "    regr_metrics['HZ'] = hz_pval\n",
    "\n",
    "    regr_metrics_all.append(regr_metrics)\n",
    "\n",
    "    # X_resid = X_resid.join(data_for_regr_cl['Код раздела'])\n",
    "    # g = sns.PairGrid(X_resid, y_vars=[\"e\"], x_vars=[\"ln_K\", \"ln_L\", \"t\"],\n",
    "    #                  hue='Код раздела', height=4)\n",
    "    # # g.map(sns.regplot, color=\".3\", ci=None)\n",
    "    # g.map(sns.scatterplot)\n",
    "    # g.set(ylim=(-1.5, 1.5), yticks=[-1.5, -1, 0, 1, 1.5])\n",
    "\n",
    "pd.set_option('display.precision', 5)\n",
    "pd.set_option('display.float_format', '{:,.5f}'.format)\n",
    "regr_metrics_all = pd.DataFrame(regr_metrics_all)\n",
    "# print(regr_metrics_all)\n",
    "regr_metrics_all\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_table = [ \n",
    "    ( 24, 0.881, 1.407 ),\n",
    "    ( 18, 0.708, 1.422 ),\n",
    "    ( 42, 1.15, 1.456 ),\n",
    "]\n",
    "DW_table = pd.DataFrame(DW_table, columns=['n', 'DW_L', 'DW_U'])\n",
    "DW_table['4-DW_U'] = 4 - DW_table['DW_U']\n",
    "DW_table['4-DW_L'] = 4 - DW_table['DW_L']\n",
    "DW_table = DW_table.set_index('n', drop=False)\n",
    "DW_table.loc[24, 'DW_L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECT AUTOREGRESSION\n",
    "from help_funcs import ols_ar1, OLSAR1\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.diagnostic import acorr_breusch_godfrey\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "linkage_type = 'ward'\n",
    "data_for_regr_cl = pd.merge(data_for_regr, cluster_mapping, 'inner', \"Код раздела\")\n",
    "data_for_regr_cl.loc[:, \"ROFA\":\"L\"] = data_for_regr_cl.loc[:, \"ROFA\":\"L\"].apply(lambda x: np.log(x))\n",
    "data_for_regr_cl = data_for_regr_cl.rename(columns={\"ROFA\": \"ln_ROFA\", \"K\": \"ln_K\", \"L\": \"ln_L\"})\n",
    "SSE_all = []\n",
    "# print(data_for_regr_cl[['ln_ROFA', 'ln_K', 'ln_L', 't']].corr())\n",
    "regr_metrics_all = []\n",
    "breush_godfrey_all = []\n",
    "cochrane_log_all = {}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2)\n",
    "fig.tight_layout()\n",
    "axs_indices = [(i, j) for i in range(2) for j in range(2)]\n",
    "cluster_ids = np.sort(data_for_regr_cl[linkage_type].unique())\n",
    "for axs_ind, cluster_id in zip(axs_indices, cluster_ids):\n",
    "    cluster = data_for_regr_cl[data_for_regr_cl[linkage_type] == cluster_id] \\\n",
    "        # .sort_values('t')\n",
    "\n",
    "    regr_metrics = {}\n",
    "    X = cluster.loc[:, [\"ln_K\", \"ln_L\", \"t\"]]\n",
    "    X = sm.add_constant(X)\n",
    "    Y = cluster.loc[:, [\"ln_ROFA\"]]\n",
    "    regression = sm.OLS(Y, X, hasconst=True)\n",
    "    result_OLS = regression.fit()\n",
    "\n",
    "    plot_acf(result_OLS.resid, lags=10, ax=axes[axs_ind])\n",
    "    axes[axs_ind].set_title(f'Кластер {cluster_id}')\n",
    "\n",
    "    # RECURSIVE COCHRANE-ORCUTT with P-W fix\n",
    "    def OLS_AR_n(original_model, max_lag, dw_vals=None, bg_alpha=0.05):\n",
    "        dw_l, dw_u = dw_vals\n",
    "\n",
    "        proc_log = {}\n",
    "\n",
    "        AR_n1 = original_model\n",
    "        first_lag = 2 + int(original_model.df_model)\n",
    "        for n_lags in range(0, max_lag+1):\n",
    "            e_1 = result_OLS.resid[1:].reset_index(drop=True)\n",
    "            e_0 = result_OLS.resid[:-1].reset_index(drop=True)\n",
    "\n",
    "            AR_n1_result = AR_n1.fit()\n",
    "            dw_hat = durbin_watson(AR_n1_result.resid)\n",
    "\n",
    "            if n_lags > 0:\n",
    "                bg_result = acorr_breusch_godfrey(original_model.fit(), nlags=n_lags, store=True)\n",
    "                bg_OLS_result = bg_result[4].resols\n",
    "                bg_fpvalue = bg_result[3]\n",
    "\n",
    "                tstat_pvals_all = stats.t.sf(bg_OLS_result.tvalues, bg_OLS_result.df_resid)\n",
    "                tstat_pval_lag = tstat_pvals_all[first_lag + n_lags - 1]\n",
    "            else:\n",
    "                tstat_pval_lag = np.nan\n",
    "                bg_fpvalue = np.nan\n",
    "\n",
    "            proc_step_log = {\n",
    "                # 'n lags' : n_lags,\n",
    "                'DW-stat' : dw_hat,\n",
    "                'BG t-stat p-value' : tstat_pval_lag,\n",
    "                'BG F-stat p-value' : bg_fpvalue,\n",
    "            }\n",
    "            proc_log[n_lags] = proc_step_log\n",
    "\n",
    "            aux_reg = sm.OLS(e_0, e_1)\n",
    "\n",
    "            result_aux = aux_reg.fit()\n",
    "            rho = result_aux.params[0]\n",
    "            AR_n0 = ols_ar1(AR_n1, rho)\n",
    "            AR_n1 = AR_n0\n",
    "        return(AR_n1, proc_log)\n",
    "\n",
    "    n=X[X.columns[0]].count()\n",
    "\n",
    "    max_lag = 6\n",
    "    dw_vals = (DW_table.loc[n, 'DW_L'], DW_table.loc[n, 'DW_U'])\n",
    "    OLS_AR, proc_log = OLS_AR_n(regression, max_lag, dw_vals)\n",
    "    cochrane_log_all[cluster_id] = pd.DataFrame(proc_log)\n",
    "    result_OLS = OLS_AR.fit()\n",
    "    print(result_OLS.summary())\n",
    "\n",
    "    breush_godfrey = {}\n",
    "    breush_godfrey['cluster_id'] = cluster_id\n",
    "    for p in range(1, max_lag+1):\n",
    "        fpval = sm.stats.diagnostic.acorr_breusch_godfrey(result_OLS, p)[1]\n",
    "        breush_godfrey[f'p = {p}'] = fpval\n",
    "    breush_godfrey_all.append(breush_godfrey)\n",
    "\n",
    "    regr_metrics['cluster_id'] = cluster_id\n",
    "    regr_metrics['n'] = n\n",
    "\n",
    "    white_pvalue = sm.stats.diagnostic.het_white(result_OLS.resid, X)[1]\n",
    "    regr_metrics['white_pvalue'] = white_pvalue\n",
    "\n",
    "    regr_metrics['R^2'] = result_OLS.rsquared\n",
    "    regr_metrics['f_pvalue'] = result_OLS.f_pvalue\n",
    "    \n",
    "    VIF_array = []\n",
    "    for exog_idx in range(1, regression.exog.shape[1]):\n",
    "        VIF = variance_inflation_factor(regression.exog, exog_idx)\n",
    "        VIF_array.append(round(VIF, 2))\n",
    "        regr_metrics[f'VIF_x{exog_idx}'] = VIF\n",
    "\n",
    "    regr_metrics['JB'] = jarque_bera(result_OLS.resid)[1]\n",
    "    hz, hz_pval, normal = multivariate_normality(regression.exog)\n",
    "\n",
    "    regr_metrics['HZ'] = hz_pval\n",
    "    regr_metrics_all.append(regr_metrics)\n",
    "\n",
    "    dw = sm.stats.stattools.durbin_watson(result_OLS.resid)\n",
    "    regr_metrics['DW'] = dw\n",
    "\n",
    "    # print('\\nLinkage: {l}, cluster {c}, n: {n}'.format(l=linkage_type, c=cluster_id, n=n))\n",
    "    # print(result_OLS.summary())    \n",
    "    # print('-- White\\'s test pvalue: ', white_pvalue)\n",
    "    # print('-- VIF:', VIF_array)\n",
    "\n",
    "    # X_resid = X.iloc[:, 1:]\n",
    "    # X_resid = X_resid.join(pd.DataFrame({\"e\": result_OLS.resid}))\n",
    "    # X_resid = X_resid.join(data_for_regr_cl['Код раздела'])\n",
    "    # g = sns.PairGrid(X_resid, y_vars=[\"e\"], x_vars=[\"ln_K\", \"ln_L\", \"t\"], hue='Код раздела', height=4)\n",
    "    # # g.map(sns.regplot, color=\".3\", ci=None)\n",
    "    # g.map(sns.scatterplot)\n",
    "    # g.set(ylim=(-1.5, 1.5), yticks=[-1.5, -1, 0, 1, 1.5])\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "breush_godfrey_all = pd.DataFrame(breush_godfrey_all)\n",
    "regr_metrics_all = pd.DataFrame(regr_metrics_all)\n",
    "regr_metrics_acorr = pd.DataFrame(regr_metrics_all.loc[:, [ 'cluster_id', 'n', 'DW' ]]) \\\n",
    "    .merge(DW_table.reset_index(drop=True), on='n', how='left')\n",
    "\n",
    "# cochrane_log_all = pd.DataFrame(cochrane_log_all)\n",
    "cochrane_log_all = pd.concat(cochrane_log_all, keys=cochrane_log_all.keys())\n",
    "cochrane_log_all = cochrane_log_all.rename_axis(['cluster_id', 'test'])\n",
    "cochrane_log_all.sort_values(by='cluster_id').to_clipboard(float_format=\"%.2f\", decimal=',')\n",
    "# print(regr_metrics_all)\n",
    "\n",
    "regr_metrics_acorr.sort_values('cluster_id', axis='index'). \\\n",
    "    style.format({\n",
    "        'DW': '{:.2f}',\n",
    "        'DW_L': '{:.2f}',\n",
    "        'DW_U': '{:.2f}',\n",
    "        '4-DW_U': '{:.2f}',\n",
    "        '4-DW_L': '{:.2f}',\n",
    "        }).hide(axis='index')\n",
    "\n",
    "breush_godfrey_all.sort_values(by='cluster_id', axis='index').style.format('{:.2f}') \\\n",
    "    .format('{:d}', subset=['cluster_id']).hide(axis='index')\n",
    "cochrane_log_all.sort_values(by='cluster_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_clust_g2 = data_for_regr_cl[data_for_regr_cl['ward'] == 2][\n",
    "    ['ln_ROFA', 'ln_K', 'ln_L', 't']]\n",
    "d_clust_g2.corr()\n",
    "# sns.heatmap(d_clust_g2.corr(), fmt='.2f', annot=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(d_clust_g2['ln_ROFA'], d_clust_g2['ln_K'], d_clust_g2['ln_L'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, Normalize\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "df = 3\n",
    "x = np.linspace(chi2.ppf(1e-10, df), chi2.ppf(0.999, df), 100)\n",
    "rv = chi2(df)\n",
    "d_clust_g3.loc[:, ['is_outlier', 'Код раздела']]\n",
    "ax.plot(x, rv.pdf(x), c='black')\n",
    "\n",
    "palette = sns.color_palette(n_colors=d_clust_g3['Код раздела'].nunique())\n",
    "my_cmap = ListedColormap(palette.as_hex())\n",
    "codes = d_clust_g3['Код раздела'].unique()\n",
    "industry_colors = {code: (color if code == 'G' else 'grey') for code, color in zip(codes, my_cmap.colors)}\n",
    "industry_linestyles = {code: ('dashed' if code == 'G' else 'solid') for code in codes}\n",
    "\n",
    "# for x, ymax in zip(squared_distances, rv.pdf(squared_distances)):\n",
    "for idx, obs in d_clust_g3.iterrows():\n",
    "    ax.axvline(obs['m_dist'], ymax=rv.pdf(obs['m_dist'])*4.1,\n",
    "               linestyle=industry_linestyles[obs['Код раздела']], c=industry_colors[obs['Код раздела']])\n",
    "\n",
    "x2 = np.linspace(2.2, chi2.ppf(0.999, df), 80)\n",
    "ax.fill_between(x2, rv.pdf(x2))\n",
    "plt.margins(x=0, y=0)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_clustered_full.loc[:, 'ROFA':'ward'],\n",
    "            corner=True, hue='ward', diag_kind='hist',\n",
    "            palette=sns.color_palette(n_colors=cluser_count[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_ANOVA = pd.merge(cluster_mapping, data_for_regr.loc[:, [\"Код раздела\", \"ROFA\"]], 'inner', 'Код раздела')\n",
    "for linkage_type in linkage_types:\n",
    "    groups = []\n",
    "    for group_id in data_for_ANOVA[linkage_type].unique():\n",
    "        groups.append(data_for_ANOVA[\"ROFA\"][(data_for_ANOVA[linkage_type] == group_id)].to_numpy())\n",
    "    res = stats.bartlett(*groups)\n",
    "    print('bartlett', res.pvalue)\n",
    "    res = stats.kruskal(*groups)\n",
    "    print('kruskal', res.pvalue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
